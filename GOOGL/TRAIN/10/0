

Google offers new findings on Russian disinformation across its products
Just a day before tech’s big Russia-focused Congressional hearings begin, Google  is out with a new report on the Russian government’s efforts to interfere in the U.S. presidential election across its platforms.

“While we have found only limited activity on our services, we will continue to work to prevent all of it, because there is no amount of interference that is acceptable,” Google wrote in its latest blog post on the issue, titled “Security and disinformation in the U.S. 2016 election.”

Google’s report appears to be limited to accounts with observable ties to the Internet Research Agency, a Russian state-affiliated organization that produces political disinformation and sock puppet accounts. That narrowed scope is possibly an effort to appease Congress with some hard numbers, so it’s worth keeping in mind that we don’t yet know the scope of these disinformation campaigns beyond those pre-defined parameters.

Google reports that in an examination of its ad products, it discovered only two accounts with ties to the Internet Research Agency. The two accounts had invested $4,700 into Google’s ad network (search and display ads) during the timeframe of the 2016 U.S. presidential election. Google doesn’t specify how it defined that timeframe in this particular batch of numbers.

Unlike razor-sharp ad targeting on a platform like Facebook, these ads weren’t even targeted by location or by political affiliation. Google does offer political ad segments that face “left-leaning” and “right-leaning” audiences, though in this instance the Internet Research Agency did not appear to use the feature.

Google’s report breaks its YouTube findings into their own category. Here, it found 18 channels it believed to be linked to the Russian government that featured public political videos in English. While that isn’t very many channels, they did create a cumulative 1,108 videos with 309,000 views in the U.S. from June 2015 to November of the following year. The vast majority of videos had fewer than 5,000 views.

The report also included Google’s other products, though those examinations didn’t turn up much. There’s no evidence (yet, anyway) that state-sponsored accounts used “improper methods” to boost search rankings, though anyone who’s seen fake news featured high up in their search results might rightfully have questions about how the company decides what flies in search and what doesn’t.

To wrap up its report, Google even did an analysis of Google+ that seems to suggest that Russian state actors might be posting vacation pics on the mostly abandoned social network:

“We ​found ​no ​political ​posts ​in ​English ​from ​state-linked ​actors ​on ​Google+ (there ​were some ​posts ​in ​Russian ​and ​a ​very ​small ​number ​of ​non-political ​posts).”

All three companies set to appear before the Senate Judiciary Committee and the Senate and House Intel Committees this week put out an early report previewing their expected testimony. Google’s relatively small scale findings put into perspective Facebook’s new assertion that similar content reached 126 million users on its own platform, though the situation on Twitter also appears to be at least somewhat worse than previously reported.

We’ll be following tech’s testimony to Congress this week as the companies expand on their own unwitting role in foreign disinformation campaigns during the 2016 election.
